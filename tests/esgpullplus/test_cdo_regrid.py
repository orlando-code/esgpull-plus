from pathlib import Path

import pytest

from esgpull.esgpullplus import cdo_regrid as cr


def test_process_single_file_standalone_skips_when_output_exists(tmp_path, monkeypatch):
    """
    _process_single_file_standalone should return a 'skipped' result when
    the output file already exists and overwrite=False, without calling
    into the heavy CDO pipeline.
    """

    input_file = tmp_path / "tas_2000.nc"
    input_file.write_bytes(b"dummy")
    output_dir = tmp_path / "out"
    output_dir.mkdir()

    # Expected output filename is generated by pipeline; we monkeypatch
    # CDORegridPipeline methods so we don't depend on the exact naming logic.
    fake_output = output_dir / "tas_2000_regridded.nc"
    fake_output.write_bytes(b"dummy")

    class DummyPipeline:
        def __init__(self, *args, **kwargs):
            self.stats = {}

        def _has_level_lightweight(self, file_path):
            return False

        def _generate_output_filename(self, file_path, has_level, extract_surface, extract_seafloor):
            return fake_output.name

        def regrid_file(self, *args, **kwargs):
            raise AssertionError("regrid_file should not be called when output exists")

    monkeypatch.setattr(cr, "CDORegridPipeline", DummyPipeline, raising=True)

    result = cr._process_single_file_standalone(
        file_path=input_file,
        output_dir=output_dir,
        target_resolution=(1.0, 1.0),
        target_grid="lonlat",
        weight_cache_dir=tmp_path / "weights",
        extract_surface=True,
        extract_seafloor=False,
        use_regrid_cache=True,
        use_seafloor_cache=True,
        max_memory_gb=8.0,
        chunk_size_gb=2.0,
        enable_chunking=True,
        overwrite=False,
        representative_file=None,
        verbose=False,
    )

    assert result["success"] is True
    assert result["skipped"] is True
    assert "File already exists" in result["message"]


def test_regrid_single_file_both_levels_uses_two_pipelines(monkeypatch, tmp_path):
    """
    regrid_single_file_both_levels should invoke two CDORegridPipeline
    instances: one for top-level and one for seafloor extraction.
    """

    input_file = tmp_path / "tas_2000.nc"
    input_file.write_bytes(b"dummy")
    output_dir = tmp_path / "out"
    output_dir.mkdir()

    created_pipelines = []
    called_regrid = []

    class DummyPipeline:
        def __init__(self, *args, **kwargs):
            created_pipelines.append(kwargs)
            self.stats = {}

        def regrid_file(self, input_path, output_path=None, force_regenerate_weights=False, overwrite=False, ui=None):
            called_regrid.append((input_path, output_path, kwargs_snapshot(self)))
            return True

    def kwargs_snapshot(pipeline):
        # Helper to snapshot distinguishing attributes
        return {
            "extract_surface": getattr(pipeline, "extract_surface", None),
            "extract_seafloor": getattr(pipeline, "extract_seafloor", None),
        }

    monkeypatch.setattr(cr, "CDORegridPipeline", DummyPipeline, raising=True)

    status = cr.regrid_single_file_both_levels(
        input_path=input_file,
        output_dir=output_dir,
        target_resolution=(1.0, 1.0),
        verbose=False,
        cleanup_weights=False,
        overwrite=False,
    )

    # Two pipelines should have been created: one seafloor, one surface (order: seafloor then surface)
    assert len(created_pipelines) == 2

    # Both branches should report success
    assert status == {"top_level": True, "seafloor": True}

